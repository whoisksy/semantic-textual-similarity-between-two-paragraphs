{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>savvy searchers fail to spot ads internet sear...</td>\n",
       "      <td>newcastle 2-1 bolton kieron dyer smashed home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>millions to miss out on the net by 2025  40% o...</td>\n",
       "      <td>nasdaq planning $100m share sale the owner of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>young debut cut short by ginepri fifteen-year-...</td>\n",
       "      <td>ruddock backs yapp s credentials wales coach m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>diageo to buy us wine firm diageo  the world s...</td>\n",
       "      <td>mci shares climb on takeover bid shares in us ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>be careful how you code a new european directi...</td>\n",
       "      <td>media gadgets get moving pocket-sized devices ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique_ID                                              text1  \\\n",
       "0          0  savvy searchers fail to spot ads internet sear...   \n",
       "1          1  millions to miss out on the net by 2025  40% o...   \n",
       "2          2  young debut cut short by ginepri fifteen-year-...   \n",
       "3          3  diageo to buy us wine firm diageo  the world s...   \n",
       "4          4  be careful how you code a new european directi...   \n",
       "\n",
       "                                               text2  \n",
       "0  newcastle 2-1 bolton kieron dyer smashed home ...  \n",
       "1  nasdaq planning $100m share sale the owner of ...  \n",
       "2  ruddock backs yapp s credentials wales coach m...  \n",
       "3  mci shares climb on takeover bid shares in us ...  \n",
       "4  media gadgets get moving pocket-sized devices ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Text_Similarity_Dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Function to remove punctuation, stopwords and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "  return [word for word in text if word.isalpha()]\n",
    "\n",
    "def remove_punctuation_from_word(text):\n",
    "  token = []\n",
    "  for word in text:\n",
    "    if word[-1].isalpha():\n",
    "      token.append(word)\n",
    "    else:\n",
    "      token.append(word[:-1]) \n",
    "  return token\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "def remove_stopword(text):\n",
    "  return [w for w in text if not w in stop_words]\n",
    "    \n",
    "def lemmatizing(text):\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  return [lemmatizer.lemmatize(word) for word in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert to lowercase -> tokenization -> removing punctuation -> removing stop words -> Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessText(raw_text):\n",
    "    processed_text = data[raw_text]\n",
    "\n",
    "    print('Converting to lower case...')\n",
    "    processed_text = [text.strip().lower() for text in processed_text]\n",
    "    print('Done')\n",
    "\n",
    "    print('Tokenizing...')\n",
    "    processed_text = [word_tokenize(text) for text in processed_text]\n",
    "    print('Done')\n",
    "\n",
    "    print('Removing punctuation...')\n",
    "    processed_text = [remove_punctuation(text) for text in processed_text]\n",
    "    processed_text = [remove_punctuation_from_word(text) for text in processed_text]\n",
    "    print('Done')\n",
    "\n",
    "    print('Removing Stop words...')\n",
    "    processed_text = [remove_stopword(text) for text in processed_text]\n",
    "    print('Done')\n",
    "\n",
    "    print('Lemmatizing...')\n",
    "    processed_text = [lemmatizing(text) for text in processed_text]\n",
    "    \n",
    "    processed_text = [' '.join(text) for text in processed_text]\n",
    "    \n",
    "    print('Text pre-processing Done, ', raw_text, '\\n')\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to lower case...\n",
      "Done\n",
      "Tokenizing...\n",
      "Done\n",
      "Removing punctuation...\n",
      "Done\n",
      "Removing Stop words...\n",
      "Done\n",
      "Lemmatizing...\n",
      "Text pre-processing Done,  text1 \n",
      "\n",
      "Converting to lower case...\n",
      "Done\n",
      "Tokenizing...\n",
      "Done\n",
      "Removing punctuation...\n",
      "Done\n",
      "Removing Stop words...\n",
      "Done\n",
      "Lemmatizing...\n",
      "Text pre-processing Done,  text2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data['preprocessedText1'] = preprocessText('text1')\n",
    "data['preprocessedText2'] = preprocessText('text2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>preprocessedText1</th>\n",
       "      <th>preprocessedText2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>savvy searchers fail to spot ads internet sear...</td>\n",
       "      <td>newcastle 2-1 bolton kieron dyer smashed home ...</td>\n",
       "      <td>savvy searcher fail spot ad internet search en...</td>\n",
       "      <td>newcastle bolton kieron dyer smashed home winn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>millions to miss out on the net by 2025  40% o...</td>\n",
       "      <td>nasdaq planning $100m share sale the owner of ...</td>\n",
       "      <td>million miss net uk population still without i...</td>\n",
       "      <td>nasdaq planning share sale owner nasdaq stock ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>young debut cut short by ginepri fifteen-year-...</td>\n",
       "      <td>ruddock backs yapp s credentials wales coach m...</td>\n",
       "      <td>young debut cut short ginepri donald young fir...</td>\n",
       "      <td>ruddock back yapp credential wale coach mike r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>diageo to buy us wine firm diageo  the world s...</td>\n",
       "      <td>mci shares climb on takeover bid shares in us ...</td>\n",
       "      <td>diageo buy u wine firm diageo world biggest sp...</td>\n",
       "      <td>mci share climb takeover bid share u phone com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>be careful how you code a new european directi...</td>\n",
       "      <td>media gadgets get moving pocket-sized devices ...</td>\n",
       "      <td>careful code new european directive could put ...</td>\n",
       "      <td>medium gadget get moving device let people car...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique_ID                                              text1  \\\n",
       "0          0  savvy searchers fail to spot ads internet sear...   \n",
       "1          1  millions to miss out on the net by 2025  40% o...   \n",
       "2          2  young debut cut short by ginepri fifteen-year-...   \n",
       "3          3  diageo to buy us wine firm diageo  the world s...   \n",
       "4          4  be careful how you code a new european directi...   \n",
       "\n",
       "                                               text2  \\\n",
       "0  newcastle 2-1 bolton kieron dyer smashed home ...   \n",
       "1  nasdaq planning $100m share sale the owner of ...   \n",
       "2  ruddock backs yapp s credentials wales coach m...   \n",
       "3  mci shares climb on takeover bid shares in us ...   \n",
       "4  media gadgets get moving pocket-sized devices ...   \n",
       "\n",
       "                                   preprocessedText1  \\\n",
       "0  savvy searcher fail spot ad internet search en...   \n",
       "1  million miss net uk population still without i...   \n",
       "2  young debut cut short ginepri donald young fir...   \n",
       "3  diageo buy u wine firm diageo world biggest sp...   \n",
       "4  careful code new european directive could put ...   \n",
       "\n",
       "                                   preprocessedText2  \n",
       "0  newcastle bolton kieron dyer smashed home winn...  \n",
       "1  nasdaq planning share sale owner nasdaq stock ...  \n",
       "2  ruddock back yapp credential wale coach mike r...  \n",
       "3  mci share climb takeover bid share u phone com...  \n",
       "4  medium gadget get moving device let people car...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf-idf\n",
    "vectorizer = TfidfVectorizer(max_df = 0.7, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD\n",
    "svd_model = TruncatedSVD(n_components=500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the pipeline\n",
    "svd_transformer = Pipeline([('tfidf', vectorizer), \n",
    "                            ('svd', svd_model)])\n",
    "\n",
    "preprocessing_model = svd_transformer.fit(data['preprocessedText1'])\n",
    "svd_matrix_text1 = preprocessing_model.transform(data['preprocessedText1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13038022, -0.05806473,  0.10923112, ...,  0.00219219,\n",
       "         0.02861354, -0.00092971],\n",
       "       [ 0.21136546, -0.04948473,  0.14078525, ..., -0.00179285,\n",
       "        -0.00678844, -0.02985562],\n",
       "       [ 0.11871561, -0.09289399, -0.09025369, ..., -0.03254321,\n",
       "         0.01996912, -0.01782526],\n",
       "       ...,\n",
       "       [ 0.20019237, -0.11674107,  0.17087802, ..., -0.0148589 ,\n",
       "         0.06638511,  0.0343965 ],\n",
       "       [ 0.10248629, -0.08296658, -0.12404679, ...,  0.00418456,\n",
       "        -0.0093032 , -0.00147784],\n",
       "       [ 0.13477473,  0.04053834,  0.02371042, ..., -0.00181597,\n",
       "         0.04251643, -0.01510969]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_matrix_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_matrix_text2 = preprocessing_model.transform(data['preprocessedText2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0952887 , -0.06371367, -0.06538803, ..., -0.01451218,\n",
       "         0.03646627, -0.02733624],\n",
       "       [ 0.11029573, -0.0364291 ,  0.1113235 , ..., -0.01916614,\n",
       "        -0.00723677, -0.00316568],\n",
       "       [ 0.13228073, -0.08848359, -0.11273877, ..., -0.01340538,\n",
       "        -0.01441074,  0.00462056],\n",
       "       ...,\n",
       "       [ 0.15917015, -0.02948292, -0.05557423, ..., -0.00390803,\n",
       "        -0.01013385, -0.02614684],\n",
       "       [ 0.11200663, -0.01919764,  0.07753895, ...,  0.00991106,\n",
       "        -0.01260567,  0.00884597],\n",
       "       [ 0.10538562, -0.04802579, -0.0397895 , ...,  0.01014282,\n",
       "        -0.00649919,  0.01959902]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_matrix_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating cosine similarity\n",
    "distance_matrix = cosine_similarity(svd_matrix_text1, svd_matrix_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4013</th>\n",
       "      <th>4014</th>\n",
       "      <th>4015</th>\n",
       "      <th>4016</th>\n",
       "      <th>4017</th>\n",
       "      <th>4018</th>\n",
       "      <th>4019</th>\n",
       "      <th>4020</th>\n",
       "      <th>4021</th>\n",
       "      <th>4022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094483</td>\n",
       "      <td>0.037588</td>\n",
       "      <td>0.046469</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.045913</td>\n",
       "      <td>0.073277</td>\n",
       "      <td>0.057745</td>\n",
       "      <td>0.057094</td>\n",
       "      <td>0.051648</td>\n",
       "      <td>0.054302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.056583</td>\n",
       "      <td>0.055410</td>\n",
       "      <td>0.053447</td>\n",
       "      <td>0.036963</td>\n",
       "      <td>0.047756</td>\n",
       "      <td>0.054306</td>\n",
       "      <td>0.045959</td>\n",
       "      <td>0.045832</td>\n",
       "      <td>0.042054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094294</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.074806</td>\n",
       "      <td>0.052279</td>\n",
       "      <td>0.081849</td>\n",
       "      <td>0.057937</td>\n",
       "      <td>0.056372</td>\n",
       "      <td>0.044149</td>\n",
       "      <td>0.081578</td>\n",
       "      <td>0.126940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052213</td>\n",
       "      <td>0.086241</td>\n",
       "      <td>0.084513</td>\n",
       "      <td>0.082841</td>\n",
       "      <td>0.045273</td>\n",
       "      <td>0.076690</td>\n",
       "      <td>0.090515</td>\n",
       "      <td>0.071822</td>\n",
       "      <td>0.052665</td>\n",
       "      <td>0.094181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.107111</td>\n",
       "      <td>0.030294</td>\n",
       "      <td>0.097587</td>\n",
       "      <td>0.026388</td>\n",
       "      <td>0.068697</td>\n",
       "      <td>0.131733</td>\n",
       "      <td>0.088121</td>\n",
       "      <td>0.016347</td>\n",
       "      <td>0.070694</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336833</td>\n",
       "      <td>0.054534</td>\n",
       "      <td>0.087848</td>\n",
       "      <td>0.046271</td>\n",
       "      <td>0.060678</td>\n",
       "      <td>0.045976</td>\n",
       "      <td>0.046595</td>\n",
       "      <td>0.108936</td>\n",
       "      <td>0.062854</td>\n",
       "      <td>0.068017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075733</td>\n",
       "      <td>0.095130</td>\n",
       "      <td>0.054825</td>\n",
       "      <td>0.073007</td>\n",
       "      <td>0.051497</td>\n",
       "      <td>0.215482</td>\n",
       "      <td>0.044662</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.047583</td>\n",
       "      <td>0.171874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033663</td>\n",
       "      <td>0.045393</td>\n",
       "      <td>0.068774</td>\n",
       "      <td>0.041549</td>\n",
       "      <td>0.052339</td>\n",
       "      <td>0.128138</td>\n",
       "      <td>0.050941</td>\n",
       "      <td>0.072003</td>\n",
       "      <td>0.081286</td>\n",
       "      <td>0.055311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085867</td>\n",
       "      <td>0.066192</td>\n",
       "      <td>0.068789</td>\n",
       "      <td>0.037187</td>\n",
       "      <td>0.093613</td>\n",
       "      <td>0.091134</td>\n",
       "      <td>0.087874</td>\n",
       "      <td>0.068217</td>\n",
       "      <td>0.065856</td>\n",
       "      <td>0.071569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026047</td>\n",
       "      <td>0.104515</td>\n",
       "      <td>0.063861</td>\n",
       "      <td>0.090001</td>\n",
       "      <td>0.056884</td>\n",
       "      <td>0.059392</td>\n",
       "      <td>0.089292</td>\n",
       "      <td>0.073110</td>\n",
       "      <td>0.060667</td>\n",
       "      <td>0.079991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4023 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.094483  0.037588  0.046469  0.018000  0.045913  0.073277  0.057745   \n",
       "1  0.094294  0.081000  0.074806  0.052279  0.081849  0.057937  0.056372   \n",
       "2  0.107111  0.030294  0.097587  0.026388  0.068697  0.131733  0.088121   \n",
       "3  0.075733  0.095130  0.054825  0.073007  0.051497  0.215482  0.044662   \n",
       "4  0.085867  0.066192  0.068789  0.037187  0.093613  0.091134  0.087874   \n",
       "\n",
       "       7         8         9     ...      4013      4014      4015      4016  \\\n",
       "0  0.057094  0.051648  0.054302  ...  0.028868  0.056583  0.055410  0.053447   \n",
       "1  0.044149  0.081578  0.126940  ...  0.052213  0.086241  0.084513  0.082841   \n",
       "2  0.016347  0.070694  0.070338  ...  0.336833  0.054534  0.087848  0.046271   \n",
       "3  0.016908  0.047583  0.171874  ...  0.033663  0.045393  0.068774  0.041549   \n",
       "4  0.068217  0.065856  0.071569  ...  0.026047  0.104515  0.063861  0.090001   \n",
       "\n",
       "       4017      4018      4019      4020      4021      4022  \n",
       "0  0.036963  0.047756  0.054306  0.045959  0.045832  0.042054  \n",
       "1  0.045273  0.076690  0.090515  0.071822  0.052665  0.094181  \n",
       "2  0.060678  0.045976  0.046595  0.108936  0.062854  0.068017  \n",
       "3  0.052339  0.128138  0.050941  0.072003  0.081286  0.055311  \n",
       "4  0.056884  0.059392  0.089292  0.073110  0.060667  0.079991  \n",
       "\n",
       "[5 rows x 4023 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_matrix = pd.DataFrame(distance_matrix)\n",
    "x = distance_matrix.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "distance_matrix = pd.DataFrame(x_scaled)\n",
    "distance_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>Similarity_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.094483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.081000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.097587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.073007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.093613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique_ID  Similarity_Score\n",
       "0          0          0.094483\n",
       "1          1          0.081000\n",
       "2          2          0.097587\n",
       "3          3          0.073007\n",
       "4          4          0.093613"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(np.diag(distance_matrix), index=[distance_matrix.index, distance_matrix.columns])\n",
    "result = result.reset_index()\n",
    "result.drop('level_0', axis=1, inplace=True)\n",
    "result.columns = ['Unique_ID', 'Similarity_Score']\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEXT: \n",
    "* To try Run the SVD Model independently and explore the model attributes : singular_values_, explained_variance_, explained_variance_ratio_, singular_values_\n",
    "* Try different model other than cosine similarity, also deep learning model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
